Learning with Sequential Data

RNNs Instead of CNNs
- Recurrent Neural Networks (RNNs) are designed to handle sequential data, unlike Convolutional Neural Networks (CNNs).
- Example: Given historical ridership data (e.g. from the Chicago Transit Authority), predict the next day's rider count.

Recognizing Patterns in Time Series

Translation as Prediction
- If there's an obvious weekly pattern, your best initial guess for a future week might be to copy the previous week's values.
- These repeated patterns are known as seasonalities.

Value of Error Visualization
- Visualizing prediction errors can easily highlight outliers.
  - Example: A large spike in error on Memorial Day likely signals behavior that didn’t match the seasonal trend.

* * * * * * * * * * * * * * * * * * * *

Statistical Time Series Models

ARMA (AutoRegressive Moving Average)
- A classic statistical model used for forecasting time series.
- Components:
  - ŷ(t): Forecast at time step t
  - y(t): Actual value at time t
  - αᵢ: Learned weights for past values (AutoRegressive part)
  - θᵢ: Learned weights for past errors (Moving Average part)
  - p: How many past values to use (lookback for trends)
  - q: How many past errors to use (lookback for residuals (errors))
  - p and q are hyperparameters, and don’t need to be equal.

SARIMA: Seasonal ARIMA
- ARMA does not explicitly model seasonality.
- SARIMA extends ARMA by explicitly modeling seasonal patterns.
- Adds:
  - P and Q: Seasonal analogues of p and q, operating over entire seasons (s).
- Best used with stationary (flat) sequences.
  - If data is not stationary, apply a derivative (1st, 2nd, etc.) to model the change instead of raw values.