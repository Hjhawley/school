Optimizers
The purpose of an optimizer is to minimize the loss more quickly (in fewer epochs) while still reaching an optimal solution.

Stochastic Gradient Descent (SGD)
An iterative method for optimizing an objective function by approximating the true gradient with a randomly chosen subset of data. 
This greatly reduces computational cost (compared to full-batch gradient descent) at the expense of a slower convergence rate.

Common Extensions and Variants of SGD
1. Learning Rate Schedule
	Gradually decrease the learning rate (η) over time for more precise updates as training progresses.
2. Momentum (β)
	Adds a fraction of the previous update (ex, 0.9) to the current update to help the model escape local minima or flat regions.
3. Nesterov Accelerated Gradient (NAG)
	A variant of momentum that looks ahead before updating weights, often leading to faster convergence ('nesterov=True').
4. Adagrad
	Adapts the gradient based on its historical magnitudes in different directions, scaling the learning rate for each parameter.
5. RMSProp
	Divides the learning rate by a moving average of recent gradient magnitudes ('RMSprop(rho=0.9)') to stabilize updates.
6. Adam (Adaptive Moment Estimation)
	Combines ideas from momentum and RMSProp, adjusting the learning rate for each parameter based on past gradients ('Adam(beta_1=0.9, beta_2=0.999)'). 
	Often the default choice for many tasks.

- SGD + Momentum: Good improvement over basic SGD
- RMSProp: Often better for non-stationary objectives
- Adam: Very popular and generally a great default

* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *

Regularization
Regularization helps prevent overfitting by improving a model’s ability to generalize beyond the training data.

- L1 Regularization (Lasso)
	Minimizes the absolute values of coefficients, causing some of them to shrink to zero, effectively eliminating unimportant features.
- L2 Regularization (Ridge)
	Minimizes the squared values of coefficients, keeping them small but not necessarily zero.
- Early Stopping
	Stops training when validation performance starts to worsen, preventing the model from memorizing the training data.
- Dropout
	Randomly “drops” (ignores) neurons during training (with a specified rate, 50%), which simulates training multiple network architectures at once and improves generalization.