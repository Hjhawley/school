üéí 0/1 Knapsack Problem (Dynamic Programming)

üîç Problem Definition
- Given 'n' items, each with:
  - Weight 'w·µ¢ > 0'
  - Value 'v·µ¢ > 0'
- Knapsack has capacity 'W'.
- Goal: Select a subset of items such that:
  - Total weight ‚â§ 'W'
  - Total value is maximized



‚ùå Why Greedy Fails
- A greedy strategy (e.g. picking items with highest 'v·µ¢ / w·µ¢' ratio) does not guarantee optimality.
- Counterexample:
  - Greedy might choose items '{5, 2, 1}' with total value 35,
  - But optimal subset '{3, 4}' has total value 40.



üß† Dynamic Programming Approach

üö´ False Start (Incorrect State):
- 'OPT(i)' = best value using first 'i' items.
- ‚ùó Problem: Doesn‚Äôt account for remaining capacity ‚Äî insufficient state information.

‚úÖ Correct State Definition:
- Let 'OPT(i, w)' = best value achievable using the first 'i' items and capacity 'w'.

üîÅ Recurrence Relation:

If w·µ¢ > w:
    OPT(i, w) = OPT(i-1, w)                   # Item i doesn't fit
Else:
    OPT(i, w) = max(
        OPT(i-1, w),                          # Don't take item i
        v·µ¢ + OPT(i-1, w - w·µ¢)                 # Take item i
    )


üßÆ Table Construction
- Use bottom-up DP: 2D table of size '(n+1) √ó (W+1)'
- Base case: 'OPT(0, w) = 0' for all 'w' (0 items = 0 value)
- Fill table row-by-row, iterating:
  - 'i = 1 to n'
  - 'w = 0 to W'



üßæ Finding the Optimal Item Subset
- Backtrack from 'OPT(n, W)':
  - If 'OPT(i, w) ‚â† OPT(i-1, w)', then item 'i' was included.
  - Subtract 'w·µ¢' and move to 'OPT(i-1, w - w·µ¢)'.



‚è± Runtime Analysis
- Time: O(nW)
- Why pseudo-polynomial?
  - Input size is 'O(n + log W)' (binary encoding of 'W')
  - But runtime is proportional to numeric value 'W', not its bit-length
  - So it's exponential in input size, hence pseudo-polynomial



üìç Bellman-Ford Algorithm (Shortest Paths with Negative Weights)

üîç Problem Definition
- Given a directed weighted graph 'G = (V, E)' and a source 's'
- Edge weights 'c(u, v)' can be negative
- Goal: Compute shortest paths from 's' to all vertices in 'V'



‚ùå Why Not Dijkstra?
- Dijkstra assumes once a node is visited with the shortest path, it's final.
- This fails when negative weights allow future paths to improve previously finalized paths.



‚úÖ Dynamic Programming Formulation
- Let 'OPT(v, i)' = length of the shortest path from 's' to 'v' using at most 'i' edges

üßæ Initialization:

For all v in V:
    OPT[v][0] = ‚àû
OPT[s][0] = 0


üîÅ Recurrence:

For i = 1 to n-1:
    For each vertex v:
        OPT[v][i] = OPT[v][i-1]
        For each edge (u, v):
            OPT[v][i] = min(
                OPT[v][i],
                OPT[u][i-1] + c(u, v)
            )


- After 'n-1' iterations, 'OPT[v][n-1]' holds the shortest distance (since no simple path has more than 'n-1' edges).



‚ö†Ô∏è Negative Cycle Detection
- Run the algorithm up to '2n' iterations.
- If any 'OPT[v][2n] ‚â† OPT[v][n-1]', a negative-weight cycle is reachable from 's'.



üß† Path Reconstruction
- Maintain a 'pred[v]' array:
  - 'pred[v]' = previous node 'u' that gave the best path to 'v'
- After table completion, backtrack from each node to 's' using 'pred[v]' to reconstruct paths.



‚è± Runtime Analysis
- Time: O(nm) (n iterations over m edges)
- Space: O(n¬≤) (if full 'OPT[v][i]' table is stored; can optimize with just two rows)