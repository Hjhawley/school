(this is mostly comp theory review)

Languages
A language is defined over an alphabet, which is a finite set of characters or symbols. Examples of alphabets include the set of digits '{0-9}', uppercase letters '{A-Z}', or a mix of letters, digits, and symbols. Characters from an alphabet can be combined into strings, which are finite sequences of characters (e.g., '"342"', '"00"').
A language over an alphabet Σ is any set of strings formed from Σ. In other words, a language specifies the subset of all possible strings (sometimes called legal strings) that belong to it.

Formal Languages
Languages used by compilers or other formal systems are called formal languages. Unlike natural languages (e.g., English, Chinese)—where grammatical correctness can be somewhat fluid—formal languages have strictly defined rules. This makes them ideal for precise mathematical reasoning and automated processing.

Defining Formal Languages
Formal languages can be described using:

1. Explicit Listing
 - Sufficient when the set is small.
 - Example: {a, b, ab, ba}.

2. Descriptive Rules
 - Example: “a non-zero digit followed by zero or more digits.”

3. Regular Expressions (Regex)
 - Patterns built from symbols and operators (e.g., '*', '+', '|', '()') to define sets of strings.

Example: Regular Expressions
A regular expression can define valid strings through operators such as:
- '*' : zero or more repetitions
- '+' : one or more repetitions
- '|' : OR (choice between patterns)
- '()' : grouping for precedence

For instance, the regex '(ab){2}d+(e|fg)' defines strings that:
1. Start with “ab” exactly twice,
2. Follow with one or more “d” characters,
3. End with either “e” or “fg”.

This would match '"ababdddfg"' but not '"adeg"'.

Regular expressions define regular languages, which are one category of formal languages. More complex languages may require additional tools, such as context-free grammars (CFGs).

Grammars
A grammar is a tool for generating the legal strings of a language. Each grammar defines exactly one language; however, many different grammars can describe that same language.

Components of a Grammar
A grammar G consists of four parts:

1. Terminals: The basic symbols (alphabet) used in the language.
2. Nonterminals: Variables representing patterns that can be expanded into terminals or other nonterminals.
3. Start Symbol: A special nonterminal from which every derivation begins.
4. Production Rules: Rules describing how nonterminals can be expanded.

Example Grammar: Counting Numbers
Consider a grammar defining positive integers (i.e., counting numbers):
- Terminals: {0, 1, 2, ..., 9}
- Nonterminals: S, P, N, D
- Start Symbol: S
- Production Rules:
```
S ⇒ P | PN
P ⇒ 1 | 2 | ... | 9
N ⇒ ND | D
D ⇒ 0 | 1 | ... | 9
```

In this grammar:
- P captures a non-zero digit ('1' through '9').
- N captures one or more digits.
- S either consists of a single non-zero digit ('P') or a non-zero digit followed by more digits ('PN').

Example Derivation
A derivation shows the sequence of production steps from the start symbol to a string of only terminals. For the string '"7234"':

1. S ⇒ PN
2. P ⇒ 7, so PN ⇒ 7N
3. N ⇒ ND ⇒ NDD ⇒ DDD, and then
4. D ⇒ 2, D ⇒ 3, D ⇒ 4

Ultimately, we get "7234". This confirms that "7234" is a valid string in the language.

Testing a Grammar
A grammar is correct for a language if:
- Completeness: It generates every legal string of the language.
- Exclusivity: It rejects every string that is not legal in the language.

For example, '"255"' can be derived from S via 'PN ⇒ PND ⇒ PDD ⇒ 2DD ⇒ 25D ⇒ 255'. However, there is no valid derivation for an illegal string like '"073"'.

Machines
A machine is a device (conceptual or actual) used to test whether a given string is in a language. While grammars effectively generate legal strings, they can be inefficient for checking whether a string is legal. Machines are optimized for precisely this verification task.

Finite Automata
The simplest type of machine is a finite automaton. It consists of:
- States: Nodes representing different conditions of the machine.
- Start State: The state where processing begins.
- End State(s): One or more states where a string can be accepted.
- Transition Rules: Directed edges (labeled with characters) indicating how the machine moves between states.

How Finite Automata Work
1. The machine begins in the start state.
2. It reads each character of the input string sequentially, following a valid transition (if one exists) to another state.
3. If at any point, no valid transition exists for the current character, the string is rejected.
4. If all characters are read and the machine ends in an end state, the string is accepted.

Finite Automata can test regular languages. 
Regular languages can be described using regular expressions and are recognized by 
deterministic finite automata (DFA) or nondeterministic finite automata (NFA) 
which are equally expressive.

Example of a language FA can test:
The language of strings containing only an even number of 0s over the alphabet {0, 1}.
Regular expression: (1*01*0)*1*
Finite automata work because you only need to keep track of whether the count of 0s is even or odd - a finite amount of memory.

Pushdown Automata
PDAs can test context-free languages (CFLs), which include regular languages but also more complex patterns involving nested structures. 
PDAs have an infinite stack, enabling them to handle some forms of recursion and matching.

Example of a language a PDA can test that a FA cannot:
    The language of balanced parentheses:
    L={w∣w contains correctly nested parentheses, e.g., (),(()),(()()),...}
    Why a FA fails: FAs lack memory to track the nested structure and can't "remember" how many open parentheses need closing.
    Why a PDA works: The stack can push each "(" and pop it when a ")" is encountered.

Turing Machines
TMs can test recursively enumerable languages (RE languages), which include 
context-free languages but also languages requiring unlimited memory and arbitrary computation.

Example of a language a TM can test that a PDA cannot:
    The language of palindromes over the alphabet {a, b}:
    L={w∣w=w^R} where w^R is the reverse of w.
    Example strings: abba, racecar, aabaa.
    Why a PDA fails: A PDA can't compare arbitrary parts of the input string since it can only access the top of the stack.
    Why a TM works: A Turing Machine can move back and forth along the tape, compare characters, and use infinite memory if needed.

To recap:

    Finite automata are the simplest machines, capable of recognizing regular languages.
    Push-down automata are more powerful, able to recognize context-free languages.
    Turing machines are the most powerful and can recognize all languages that are recognizable.

A problem that cannot be solved by a FA requires at least a PDA, and if a PDA is 
insufficient, a TM is necessary. There are no intermediate machines between these categories.

(Language)      (Grammar)       (Machine)
Unrestricted    Unrestricted    Turing Machine
Context Free    Context Free    Push Down Automata
Regular         Regular         Finite Automata